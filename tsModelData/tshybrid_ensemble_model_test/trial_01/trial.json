{"trial_id": "01", "hyperparameters": {"space": [{"class_name": "Int", "config": {"name": "lstm_units", "default": null, "conditions": [], "min_value": 32, "max_value": 128, "step": 32, "sampling": "linear"}}, {"class_name": "Int", "config": {"name": "lstm_dense_units", "default": null, "conditions": [], "min_value": 32, "max_value": 128, "step": 32, "sampling": "linear"}}, {"class_name": "Int", "config": {"name": "cnn_filters", "default": null, "conditions": [], "min_value": 32, "max_value": 128, "step": 32, "sampling": "linear"}}, {"class_name": "Choice", "config": {"name": "cnn_kernel_size", "default": 3, "conditions": [], "values": [3, 5], "ordered": true}}, {"class_name": "Int", "config": {"name": "cnn_dense_units", "default": null, "conditions": [], "min_value": 32, "max_value": 128, "step": 32, "sampling": "linear"}}, {"class_name": "Int", "config": {"name": "gru_units", "default": null, "conditions": [], "min_value": 32, "max_value": 128, "step": 32, "sampling": "linear"}}, {"class_name": "Int", "config": {"name": "gru_dense_units", "default": null, "conditions": [], "min_value": 32, "max_value": 128, "step": 32, "sampling": "linear"}}, {"class_name": "Int", "config": {"name": "transformer_embed_dim", "default": null, "conditions": [], "min_value": 32, "max_value": 128, "step": 32, "sampling": "linear"}}, {"class_name": "Int", "config": {"name": "transformer_num_heads", "default": null, "conditions": [], "min_value": 2, "max_value": 8, "step": 2, "sampling": "linear"}}, {"class_name": "Int", "config": {"name": "transformer_ff_dim", "default": null, "conditions": [], "min_value": 32, "max_value": 128, "step": 32, "sampling": "linear"}}, {"class_name": "Int", "config": {"name": "transformer_dense_units", "default": null, "conditions": [], "min_value": 32, "max_value": 128, "step": 32, "sampling": "linear"}}, {"class_name": "Int", "config": {"name": "ensemble_dense_units", "default": null, "conditions": [], "min_value": 64, "max_value": 256, "step": 64, "sampling": "linear"}}, {"class_name": "Float", "config": {"name": "dropout_rate", "default": 0.2, "conditions": [], "min_value": 0.2, "max_value": 0.5, "step": 0.1, "sampling": "linear"}}, {"class_name": "Float", "config": {"name": "learning_rate", "default": 0.0001, "conditions": [], "min_value": 0.0001, "max_value": 0.01, "step": null, "sampling": "log"}}], "values": {"lstm_units": 128, "lstm_dense_units": 96, "cnn_filters": 64, "cnn_kernel_size": 3, "cnn_dense_units": 32, "gru_units": 32, "gru_dense_units": 64, "transformer_embed_dim": 96, "transformer_num_heads": 8, "transformer_ff_dim": 96, "transformer_dense_units": 64, "ensemble_dense_units": 64, "dropout_rate": 0.2, "learning_rate": 0.0029611918471381376}}, "metrics": {"metrics": {}}, "score": null, "best_step": 0, "status": "FAILED", "message": "Traceback (most recent call last):\n  File \"C:\\Users\\shepa\\OneDrive\\8.0 Projects\\8.3 ProjectModelsEquinox\\EQUINRUN\\PythonLib\\.venv\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 274, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"C:\\Users\\shepa\\OneDrive\\8.0 Projects\\8.3 ProjectModelsEquinox\\EQUINRUN\\PythonLib\\.venv\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 239, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\shepa\\OneDrive\\8.0 Projects\\8.3 ProjectModelsEquinox\\EQUINRUN\\PythonLib\\.venv\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 314, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\shepa\\OneDrive\\8.0 Projects\\8.3 ProjectModelsEquinox\\EQUINRUN\\PythonLib\\.venv\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 232, in _build_and_fit_model\n    model = self._try_build(hp)\n            ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\shepa\\OneDrive\\8.0 Projects\\8.3 ProjectModelsEquinox\\EQUINRUN\\PythonLib\\.venv\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 164, in _try_build\n    model = self._build_hypermodel(hp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\shepa\\OneDrive\\8.0 Projects\\8.3 ProjectModelsEquinox\\EQUINRUN\\PythonLib\\.venv\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 155, in _build_hypermodel\n    model = self.hypermodel.build(hp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\shepa\\OneDrive\\8.0 Projects\\8.3 ProjectModelsEquinox\\EQUINRUN\\PythonLib\\.venv\\Lib\\site-packages\\keras_tuner\\src\\engine\\hypermodel.py\", line 120, in _build_wrapper\n    return self._build(hp, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\shepa\\OneDrive\\8.0 Projects\\8.3 ProjectModelsEquinox\\EQUINRUN\\PythonLib\\.venv\\Lib\\site-packages\\tsMqlMLTune.py\", line 103, in build\n    lstm_output = build_lstm()\n                  ^^^^^^^^^^^^\n  File \"C:\\Users\\shepa\\OneDrive\\8.0 Projects\\8.3 ProjectModelsEquinox\\EQUINRUN\\PythonLib\\.venv\\Lib\\site-packages\\tsMqlMLTune.py\", line 65, in build_lstm\n    x = Dense(hp.Int('lstm_dense_units', 32, 128, step=32), activation='relu')(x)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\shepa\\OneDrive\\8.0 Projects\\8.3 ProjectModelsEquinox\\EQUINRUN\\PythonLib\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\shepa\\OneDrive\\8.0 Projects\\8.3 ProjectModelsEquinox\\EQUINRUN\\PythonLib\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\random.py\", line 34, in uniform\n    return tf.random.stateless_uniform(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: {{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} OOM when allocating tensor with shape[10233856,96] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu [Op:Mul] name: \n"}